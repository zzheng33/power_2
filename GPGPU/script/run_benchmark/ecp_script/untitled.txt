TF_XLA_FLAGS='--tf_xla_auto_jit=2' python3 ./run_pretraining.py \
        --bert_config_file=./input_files/bert_config.json \
        --output_dir=/tmp/output/ \
        --input_file=./6000_samples \
        --do_train=True \
        --iterations_per_loop=1000 \
        --learning_rate=0.0001 \
        --max_eval_steps=1250 \
        --max_predictions_per_seq=76 \
        --max_seq_length=512 \
        --num_gpus=1 \
        --num_train_steps=750 \
        --num_warmup_steps=0 \
        --optimizer=lamb \
        --save_checkpoints_steps=156200000 \
        --start_warmup_step=0 \
        --train_batch_size=8\
        --nouse_tpu