{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a443fe76-9108-481a-bcc4-096fc679a948",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor (with NaNs):\n",
      "[[[100.75 110.9     nan]\n",
      "  [126.   116.1     nan]]\n",
      "\n",
      " [[ 90.8  105.95    nan]\n",
      "  [141.15 151.25 146.3 ]]]\n",
      "\n",
      "Reconstructed Tensor (Predicted NaNs):\n",
      "[[[100.75000607 110.89999335 118.60554921]\n",
      "  [125.99999959 116.10000045 120.50929949]]\n",
      "\n",
      " [[ 90.79999704 105.95000324 124.62033106]\n",
      "  [141.14999793 151.25000226 146.29999822]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import parafac\n",
    "\n",
    "# Step 1: Create the Initial 3D Tensor (2x2x3) with Missing Values (NaNs)\n",
    "tensor_data = np.array([\n",
    "    [[(1.5 + 200) / 2, (1.8 + 220) / 2, np.nan],  # CPU 100, GPU 50\n",
    "     [(2.0 + 250) / 2, (2.2 + 230) / 2, np.nan]], # CPU 100, GPU 100\n",
    "\n",
    "    [[(1.6 + 180) / 2, (1.9 + 210) / 2, np.nan],  # CPU 200, GPU 50\n",
    "     [(2.3 + 280) / 2, (2.5 + 300) / 2, (2.6 + 290) / 2]]  # CPU 200, GPU 100\n",
    "])\n",
    "\n",
    "# Print the Results\n",
    "print(\"Original Tensor (with NaNs):\")\n",
    "print(tensor_data)\n",
    "\n",
    "# ðŸ”¹ Step 2: Fill NaNs with Initial Estimates (Mean Imputation)\n",
    "nan_mask = np.isnan(tensor_data)  # Identify missing values\n",
    "mean_value = np.nanmean(tensor_data) if np.any(~nan_mask) else 0  # Compute mean\n",
    "tensor_filled = tensor_data.copy()\n",
    "tensor_filled[nan_mask] = mean_value  # Fill NaNs with the mean, but keep the mask\n",
    "\n",
    "# ðŸ”¹ Step 3: Apply CP Tensor Factorization\n",
    "mask = ~nan_mask  # Use only known values for training\n",
    "rank = min(5, tensor_data.shape[2])  # Ensure enough rank for better approximation\n",
    "\n",
    "factors = parafac(tensor_filled, rank=rank, init='svd', mask=mask)  # Use 'svd' initialization\n",
    "\n",
    "# ðŸ”¹ Step 4: Reconstruct the Completed Tensor\n",
    "completed_tensor = tl.cp_to_tensor(factors)\n",
    "\n",
    "# ðŸ”¹ Step 5: Restore Missing Value Positions with CP Predictions\n",
    "tensor_data[nan_mask] = completed_tensor[nan_mask]\n",
    "\n",
    "\n",
    "print(\"\\nReconstructed Tensor (Predicted NaNs):\")\n",
    "print(completed_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ddcfb40-4362-43e8-95ce-0bba774e7b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy for pathfinder: MAE=0.0634, RMSE=0.0703, RÂ²=-0.1738\n",
      "Prediction Accuracy for where: MAE=0.0676, RMSE=0.0763, RÂ²=-0.3705\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import parafac, tucker\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Define directories\n",
    "offline_dir = \"./altis_power_cap_res/offline/\"\n",
    "online_dir = \"./altis_power_cap_res/online/\"\n",
    "\n",
    "# Get all application CSV files from offline data\n",
    "offline_csv_files = [f for f in os.listdir(offline_dir) if f.endswith(\"_performance.csv\")]\n",
    "online_csv_files = [f for f in os.listdir(online_dir) if f.endswith(\"_performance.csv\")]\n",
    "\n",
    "# Extract application names\n",
    "offline_apps = sorted([f.replace(\"_performance.csv\", \"\") for f in offline_csv_files])\n",
    "online_apps = sorted([f.replace(\"_performance.csv\", \"\") for f in online_csv_files])\n",
    "\n",
    "# Load offline data\n",
    "df_list = []\n",
    "for file in offline_csv_files:\n",
    "    app_name = file.replace(\"_performance.csv\", \"\")\n",
    "    df = pd.read_csv(os.path.join(offline_dir, file))\n",
    "    df[\"App\"] = app_name\n",
    "    df_list.append(df)\n",
    "\n",
    "df_full = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Step 1: Encode CPU Power, GPU Power, and Applications\n",
    "cpu_power_levels = sorted(df_full[\"CPU Power Cap\"].unique())\n",
    "gpu_power_levels = sorted(df_full[\"GPU Power Cap\"].unique())\n",
    "\n",
    "cpu_index_map = {power: idx for idx, power in enumerate(cpu_power_levels)}\n",
    "gpu_index_map = {power: idx for idx, power in enumerate(gpu_power_levels)}\n",
    "app_index_map = {app: idx for idx, app in enumerate(offline_apps)}\n",
    "\n",
    "num_cpu = len(cpu_power_levels)\n",
    "num_gpu = len(gpu_power_levels)\n",
    "num_apps = len(offline_apps)\n",
    "\n",
    "# Step 2: Initialize 3D Tensor (IPS + FLOPs)/2\n",
    "tensor_data = np.full((num_cpu, num_gpu, num_apps), np.nan)\n",
    "\n",
    "# Populate tensor with offline data\n",
    "for _, row in df_full.iterrows():\n",
    "    cpu_idx = cpu_index_map[row[\"CPU Power Cap\"]]\n",
    "    gpu_idx = gpu_index_map[row[\"GPU Power Cap\"]]\n",
    "    app_idx = app_index_map[row[\"App\"]]\n",
    "    tensor_data[cpu_idx, gpu_idx, app_idx] = (row[\"IPS\"] + row[\"FLOPS\"]) / 2\n",
    "\n",
    "# # Step 3: Normalize Data for Stability\n",
    "# tensor_max = np.nanmax(tensor_data)\n",
    "# tensor_data /= tensor_max  # Scale between [0, 1]\n",
    "\n",
    "# Step 4: Process Online Applications\n",
    "for file in online_csv_files:\n",
    "    app_name = file.replace(\"_performance.csv\", \"\")\n",
    "    df_online = pd.read_csv(os.path.join(online_dir, file))\n",
    "    df_online[\"App\"] = app_name\n",
    "\n",
    "    # Expand tensor (add new app dimension)\n",
    "    tensor_data = np.pad(tensor_data, ((0, 0), (0, 0), (0, 1)), constant_values=np.nan)\n",
    "    app_index_map[app_name] = tensor_data.shape[2] - 1  # Update app index\n",
    "\n",
    "    # Select 50% of rows as known values\n",
    "    df_known = df_online.sample(frac=0.1, random_state=42)\n",
    "    df_test = df_online.drop(df_known.index)\n",
    "\n",
    "    # Fill tensor with known values\n",
    "    for _, row in df_known.iterrows():\n",
    "        cpu_idx = cpu_index_map[row[\"CPU Power Cap\"]]\n",
    "        gpu_idx = gpu_index_map[row[\"GPU Power Cap\"]]\n",
    "        app_idx = app_index_map[row[\"App\"]]\n",
    "        tensor_data[cpu_idx, gpu_idx, app_idx] = (row[\"IPS\"] + row[\"FLOPS\"]) / 2 / tensor_max\n",
    "\n",
    "    # Step 5: Use SVD-Based Imputation for NaNs\n",
    "    nan_mask = np.isnan(tensor_data)\n",
    "    tensor_2d = tensor_data.reshape(-1, tensor_data.shape[-1])  # Flatten only last axis\n",
    "    \n",
    "    # Fill NaNs with the mean before SVD\n",
    "    imputer = SimpleImputer(strategy=\"mean\")\n",
    "    tensor_2d_filled = imputer.fit_transform(tensor_2d)\n",
    "    \n",
    "    # Apply SVD\n",
    "    svd = TruncatedSVD(n_components=min(3, tensor_2d_filled.shape[1]-1))\n",
    "    low_rank_approx = svd.fit_transform(tensor_2d_filled)\n",
    "    tensor_filled = svd.inverse_transform(low_rank_approx)  # Restores original structure\n",
    "    \n",
    "    # Reshape back to original tensor shape\n",
    "    tensor_filled = tensor_filled.reshape(tensor_data.shape)\n",
    "\n",
    "    # Step 6: Apply Tucker Decomposition Instead of CP\n",
    "    ranks = [min(10, tensor_data.shape[0]), min(10, tensor_data.shape[1]), min(10, tensor_data.shape[2])]\n",
    "    core, factors = tucker(tensor_filled, rank=ranks)\n",
    "    completed_tensor = tl.tucker_to_tensor((core, factors))\n",
    "\n",
    "    # Step 7: Evaluate Predictions\n",
    "    test_data = []\n",
    "    for _, row in df_test.iterrows():\n",
    "        cpu_idx = cpu_index_map[row[\"CPU Power Cap\"]]\n",
    "        gpu_idx = gpu_index_map[row[\"GPU Power Cap\"]]\n",
    "        app_idx = app_index_map[row[\"App\"]]\n",
    "        test_data.append((cpu_idx, gpu_idx, app_idx, (row[\"IPS\"] + row[\"FLOPS\"]) / 2 / tensor_max))\n",
    "\n",
    "    true_values, predicted_values = [], []\n",
    "    for cpu_idx, gpu_idx, app_idx, true_val in test_data:\n",
    "        predicted_val = completed_tensor[cpu_idx, gpu_idx, app_idx]\n",
    "        true_values.append(true_val)\n",
    "        predicted_values.append(predicted_val)\n",
    "\n",
    "    # Compute Accuracy Metrics\n",
    "    mae = mean_absolute_error(true_values, predicted_values) * tensor_max  # Rescale values\n",
    "    rmse = np.sqrt(mean_squared_error(true_values, predicted_values)) * tensor_max\n",
    "    r2 = r2_score(true_values, predicted_values)\n",
    "\n",
    "    print(f\"Prediction Accuracy for {app_name}: MAE={mae:.4f}, RMSE={rmse:.4f}, RÂ²={r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05e5004-bf2f-42bb-801e-7e04442b6882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
