{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8899c483-e062-43b8-8b3b-2aaf9fe27dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tensorflow.keras.layers import Add, LeakyReLU\n",
    "from tensorflow.keras.activations import relu\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb285c5d-2937-4201-9ea1-f4d21c9e737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# Step 1: Data Preprocessing ############################# \n",
    "\n",
    "# Define directories for training and validation data\n",
    "train_dir = \"./altis_power_cap_res/2_dual_cap/train\"\n",
    "validation_dir = \"./ecp_power_cap_res/2_dual_cap/validation\"\n",
    "save_model_dir = \"./altis_power_cap_res/2_dual_cap/model\"\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "\n",
    "# Load CSV files from train directory\n",
    "train_csv_files = [f for f in os.listdir(train_dir) if f.endswith(\".csv\")]\n",
    "validation_csv_files = [f for f in os.listdir(validation_dir) if f.endswith(\".csv\")]\n",
    "\n",
    "# Load and merge training data while filtering out specified CPU power caps\n",
    "train_data = []\n",
    "for file in train_csv_files:\n",
    "    file_path = os.path.join(train_dir, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Drop rows where CPU Power Cap is 120 or 130\n",
    "    df = df[~df[\"CPU Power Cap\"].isin([120, 130])]\n",
    "\n",
    "    train_data.append(df)\n",
    "\n",
    "# Merge all training data\n",
    "train_df = pd.concat(train_data, ignore_index=True)\n",
    "\n",
    "# Load validation data while filtering out specified CPU power caps\n",
    "validation_data = {}\n",
    "for file in validation_csv_files:\n",
    "    file_path = os.path.join(validation_dir, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Drop rows where CPU Power Cap is 120 or 130\n",
    "    df = df[~df[\"CPU Power Cap\"].isin([120, 130])]\n",
    "\n",
    "    validation_data[file] = df\n",
    "\n",
    "# Drop any rows with missing values\n",
    "train_df.dropna(inplace=True)\n",
    "for key in validation_data:\n",
    "    validation_data[key].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e27df1e4-298b-406d-97fe-f588b210b43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# Step 2: Build MLP Model ############################# \n",
    "\n",
    "# Define feature columns and target column\n",
    "feature_cols = [\"CPU Power Cap\", \"GPU Power Cap\", \"IPS\", \"Memory Throughput\", \"SM Clock\", \"DRAM Active\", \"FP Active\"]\n",
    "feature_cols = [\"CPU Power Cap\", \"GPU Power Cap\", \"Memory Throughput\", \"SM Clock\", \"DRAM Active\", \"FP Active\"]\n",
    "# feature_cols = [\"CPU Power Cap\", \"GPU Power Cap\", \"Memory Throughput\", \"SM Clock\"]\n",
    "\n",
    "target_col = \"Performance\"\n",
    "\n",
    "# Extract features and target for training\n",
    "X_train = train_df[feature_cols].values\n",
    "y_train = train_df[target_col].values.reshape(-1, 1)\n",
    "\n",
    "# Normalize features and target\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "\n",
    "# Build the improved MLP model\n",
    "# Define the MLP model properly\n",
    "model = Sequential([\n",
    "    tf.keras.Input(shape=(X_train_scaled.shape[1],)),  # Explicitly define input shape\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='selu'),\n",
    "    Dense(32, activation='selu'),\n",
    "    Dense(1, activation='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "258a5143-f2a5-4789-b897-efce63627c75",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Epoch 2/50\n",
      "Epoch 3/50\n",
      "Epoch 4/50\n",
      "Epoch 5/50\n",
      "Epoch 6/50\n",
      "Epoch 7/50\n",
      "Epoch 8/50\n",
      "Epoch 9/50\n",
      "Epoch 10/50\n",
      "Epoch 11/50\n",
      "Epoch 12/50\n",
      "Epoch 13/50\n",
      "Epoch 14/50\n",
      "Epoch 15/50\n",
      "Epoch 16/50\n",
      "Epoch 17/50\n",
      "Epoch 18/50\n",
      "Epoch 19/50\n",
      "Epoch 20/50\n",
      "Epoch 21/50\n",
      "Epoch 22/50\n",
      "Epoch 23/50\n",
      "Epoch 24/50\n",
      "Epoch 25/50\n",
      "Epoch 26/50\n",
      "Epoch 27/50\n",
      "Epoch 28/50\n",
      "Epoch 29/50\n",
      "Epoch 30/50\n",
      "Epoch 31/50\n",
      "Epoch 32/50\n",
      "Epoch 33/50\n",
      "Epoch 34/50\n",
      "Epoch 35/50\n",
      "Epoch 36/50\n",
      "Epoch 37/50\n",
      "Epoch 38/50\n",
      "Epoch 39/50\n",
      "Epoch 40/50\n",
      "Epoch 41/50\n",
      "Epoch 42/50\n",
      "Epoch 43/50\n",
      "Epoch 44/50\n",
      "Epoch 45/50\n",
      "Epoch 46/50\n",
      "Epoch 47/50\n",
      "Epoch 48/50\n",
      "Epoch 49/50\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "############################# Step 3: Train MLP Model #############################\n",
    "# Compile the model with a different optimizer\n",
    "model.compile(optimizer='nadam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train_scaled, epochs=50, batch_size=32, verbose=3)\n",
    "\n",
    "# Save the trained model\n",
    "model.save(os.path.join(save_model_dir, \"performance_prediction_model.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9951aadb-80b4-469f-8ef7-ba79b4eb3ae4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Neural Network Prediction for lammps (Sampled 20% Power Pairs, One-by-One Prediction):\n",
      "MAE: 0.0274\n",
      "Prediction Accuracy: 96.66%\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Neural Network Prediction for Resnet50 (Sampled 20% Power Pairs, One-by-One Prediction):\n",
      "MAE: 0.0228\n",
      "Prediction Accuracy: 97.54%\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Neural Network Prediction for sw4lite (Sampled 20% Power Pairs, One-by-One Prediction):\n",
      "MAE: 0.0419\n",
      "Prediction Accuracy: 95.35%\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Neural Network Prediction for Laghos (Sampled 20% Power Pairs, One-by-One Prediction):\n",
      "MAE: 0.0812\n",
      "Prediction Accuracy: 91.35%\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Neural Network Prediction for NAMD (Sampled 20% Power Pairs, One-by-One Prediction):\n",
      "MAE: 0.0386\n",
      "Prediction Accuracy: 95.19%\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Neural Network Prediction for miniGAN (Sampled 20% Power Pairs, One-by-One Prediction):\n",
      "MAE: 0.0468\n",
      "Prediction Accuracy: 94.30%\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Neural Network Prediction for gromacs (Sampled 20% Power Pairs, One-by-One Prediction):\n",
      "MAE: 0.0385\n",
      "Prediction Accuracy: 95.73%\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Neural Network Prediction for bert_large (Sampled 20% Power Pairs, One-by-One Prediction):\n",
      "MAE: 0.0419\n",
      "Prediction Accuracy: 95.03%\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Neural Network Prediction for UNet (Sampled 20% Power Pairs, One-by-One Prediction):\n",
      "MAE: 0.0319\n",
      "Prediction Accuracy: 96.26%\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Neural Network Prediction for XSBench (Sampled 20% Power Pairs, One-by-One Prediction):\n",
      "MAE: 0.0763\n",
      "Prediction Accuracy: 88.29%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "############################# Step 4: Evaluate Model Performance ############################# \n",
    "\n",
    "# Define model path and load trained model\n",
    "model_path = os.path.join(save_model_dir, \"performance_prediction_model.h5\")  # Legacy format\n",
    "model = tf.keras.models.load_model(model_path, custom_objects={\"mse\": tf.keras.losses.MeanSquaredError()})\n",
    "\n",
    "# Define feature columns and target column\n",
    "feature_cols = [\"CPU Power Cap\", \"GPU Power Cap\", \"IPS\", \"Memory Throughput\", \"SM Clock\", \"DRAM Active\", \"FP Active\"]\n",
    "feature_cols = [\"CPU Power Cap\", \"GPU Power Cap\", \"Memory Throughput\", \"SM Clock\", \"DRAM Active\", \"FP Active\"]\n",
    "# feature_cols = [\"CPU Power Cap\", \"GPU Power Cap\", \"Memory Throughput\", \"SM Clock\"]\n",
    "target_col = \"Performance\"\n",
    "\n",
    "# Iterate over validation CSV files\n",
    "for file in validation_csv_files:\n",
    "    file_path = os.path.join(validation_dir, file)\n",
    "    new_app_name = file.replace(\"_performance.csv\", \"\")\n",
    "\n",
    "    # Load validation data\n",
    "    df_new = pd.read_csv(file_path)\n",
    "    df_new[\"Power Pair\"] = list(zip(df_new[\"CPU Power Cap\"], df_new[\"GPU Power Cap\"]))\n",
    "\n",
    "    # Sample 20% of power pairs\n",
    "    df_sampled = df_new.sample(frac=0.2, random_state=seed)  # Select 20% of rows\n",
    "    sampled_pairs = df_sampled[\"Power Pair\"].unique()\n",
    "\n",
    "    true_values, nn_predicted_values, accuracy_values = [], [], []\n",
    "\n",
    "    for power_pair in sampled_pairs:\n",
    "        # Extract feature values for the selected power pair\n",
    "        X_sample = df_new[df_new[\"Power Pair\"] == power_pair][feature_cols].values\n",
    "\n",
    "        # Normalize features\n",
    "        X_sample_scaled = scaler_X.transform(X_sample)\n",
    "\n",
    "        # Predict performance\n",
    "        y_pred = model.predict(X_sample_scaled)\n",
    "        predicted_value = scaler_y.inverse_transform(y_pred)[0][0]\n",
    "\n",
    "        # Store true and predicted values\n",
    "        true_value = df_new.loc[df_new[\"Power Pair\"] == power_pair, \"Performance\"].values[0]\n",
    "        true_values.append(true_value)\n",
    "        nn_predicted_values.append(predicted_value)\n",
    "\n",
    "        # Compute percentage-based prediction accuracy\n",
    "        accuracy = 100 - (abs(true_value - predicted_value) / true_value * 100)\n",
    "        accuracy_values.append(accuracy)\n",
    "\n",
    "    # Compute evaluation metrics\n",
    "    nn_mae = mean_absolute_error(true_values, nn_predicted_values)\n",
    "    nn_rmse = np.sqrt(mean_squared_error(true_values, nn_predicted_values))\n",
    "    nn_r2 = r2_score(true_values, nn_predicted_values)\n",
    "    avg_accuracy = np.mean(accuracy_values)\n",
    "\n",
    "    # Print evaluation results\n",
    "    print(f\"Neural Network Prediction for {new_app_name} (Sampled 20% Power Pairs, One-by-One Prediction):\")\n",
    "    print(f\"MAE: {nn_mae:.4f}\")\n",
    "    print(f\"Prediction Accuracy: {avg_accuracy:.2f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19875213-da54-4e4c-b06b-e4f2fe0110cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "############################# Step 5: Populate Initial Performance Matrix ############################# \n",
    "\n",
    "model_path = os.path.join(save_model_dir, \"performance_prediction_model.h5\")  # Legacy format\n",
    "model = tf.keras.models.load_model(model_path, custom_objects={\"mse\": tf.keras.losses.MeanSquaredError()})\n",
    "# feature_cols = [\"CPU Power Cap\", \"GPU Power Cap\", \"IPS\", \"Memory Throughput\", \"SM Clock\", \"DRAM Active\", \"FP Active\"]\n",
    "feature_cols = [\"CPU Power Cap\", \"GPU Power Cap\", \"Memory Throughput\", \"SM Clock\", \"DRAM Active\", \"FP Active\"]\n",
    "# feature_cols = [\"CPU Power Cap\", \"GPU Power Cap\", \"Memory Throughput\", \"SM Clock\"]\n",
    "target_col = \"Performance\"\n",
    "\n",
    "# Dictionary to store application data\n",
    "app_data = {}\n",
    "\n",
    "# Process each CSV file (each application)\n",
    "for file in train_csv_files:\n",
    "    file_path = os.path.join(train_dir, file)\n",
    "    app_name = file.replace(\"_performance.csv\", \"\")\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    required_columns = [\"CPU Power Cap\", \"GPU Power Cap\", \"Performance\"]\n",
    "    df = df[required_columns]\n",
    "\n",
    "    # Create a unique power pair column\n",
    "    df[\"Power Pair\"] = list(zip(df[\"CPU Power Cap\"], df[\"GPU Power Cap\"]))\n",
    "    \n",
    "    # Store application data\n",
    "    app_data[app_name] = df[[\"Power Pair\", \"Performance\"]].set_index(\"Power Pair\")\n",
    "\n",
    "# Combine all applications into a single 2D matrix\n",
    "performance_matrix = pd.DataFrame(index=sorted(set().union(*[df.index for df in app_data.values()])),\n",
    "                                  columns=sorted(app_data.keys()))\n",
    "\n",
    "\n",
    "# Populate the performance matrix with training data\n",
    "for app_name, df in app_data.items():\n",
    "    performance_matrix[app_name] = df[\"Performance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d68f7644-69fc-41f7-a998-72e5c118f58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1740696941.145556  815448 service.cc:148] XLA service 0x7fbcb80040f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1740696941.145597  815448 service.cc:156]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "I0000 00:00:1740696941.180292  815448 cuda_dnn.cc:529] Loaded cuDNN version 90701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1740696941.375841  815448 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "NN Prediction for sw4lite: MAE=0.0353, Prediction Accuracy=95.92%\n",
      "Epoch 1/25\n",
      "Epoch 2/25\n",
      "Epoch 3/25\n",
      "Epoch 4/25\n",
      "Epoch 5/25\n",
      "Epoch 6/25\n",
      "Epoch 7/25\n",
      "Epoch 8/25\n",
      "Epoch 9/25\n",
      "Epoch 10/25\n",
      "Epoch 11/25\n",
      "Epoch 12/25\n",
      "Epoch 13/25\n",
      "Epoch 14/25\n",
      "Epoch 15/25\n",
      "Epoch 16/25\n",
      "Epoch 17/25\n",
      "Epoch 18/25\n",
      "Epoch 19/25\n",
      "Epoch 20/25\n",
      "Epoch 21/25\n",
      "Epoch 22/25\n",
      "Epoch 23/25\n",
      "Epoch 24/25\n",
      "Epoch 25/25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "NCF Prediction for sw4lite: MAE=0.0308, Prediction Accuracy=96.31%\n"
     ]
    }
   ],
   "source": [
    "############################# Step 6: Construct Sparse Matrix and Predict Missing Value ############################# \n",
    "\n",
    "# Directories\n",
    "save_model_dir = \"./altis_power_cap_res/2_dual_cap/model\"\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "\n",
    "# Results storage\n",
    "nn_results = []\n",
    "cf_results = []\n",
    "\n",
    "# Process each new application\n",
    "for file in validation_csv_files:\n",
    "    file_path = os.path.join(validation_dir, file)\n",
    "    new_app_name = file.replace(\"_performance.csv\", \"\")\n",
    "\n",
    "    # Load validation data\n",
    "    df_new = pd.read_csv(file_path)\n",
    "    df_new[\"Power Pair\"] = list(zip(df_new[\"CPU Power Cap\"], df_new[\"GPU Power Cap\"]))\n",
    "\n",
    "    # Add new application to performance matrix\n",
    "    performance_matrix[new_app_name] = np.nan\n",
    "\n",
    "    #############  Predict 20% of power pairs using trained NN --- Construct Sparse Matrix  ############# \n",
    "    \n",
    "    df_sampled = df_new.sample(frac=0.2, random_state=seed)  # Select 20% of rows\n",
    "    sampled_pairs = df_sampled[\"Power Pair\"].unique()\n",
    "\n",
    "    true_values, nn_predicted_values = [], []\n",
    "    for power_pair in sampled_pairs:\n",
    "        X_sample = df_new[df_new[\"Power Pair\"] == power_pair][feature_cols].values\n",
    "        X_sample_scaled = scaler_X.transform(X_sample)\n",
    "        \n",
    "        # Predict performance\n",
    "        y_pred = model.predict(X_sample_scaled)\n",
    "        predicted_value = scaler_y.inverse_transform(y_pred)[0][0]\n",
    "    \n",
    "        # Fill performance matrix with NN predictions\n",
    "        performance_matrix.at[power_pair, new_app_name] = predicted_value\n",
    "\n",
    "        # Store true and predicted values for error calculation\n",
    "        if power_pair in df_new.set_index(\"Power Pair\").index:\n",
    "            actual = df_new.loc[df_new[\"Power Pair\"] == power_pair, \"Performance\"].values[0]\n",
    "            true_values.append(actual)\n",
    "            nn_predicted_values.append(predicted_value)\n",
    "    \n",
    "    ############## Compute NN Prediction Accuracy ##############\n",
    "    \n",
    "    nn_mae = mean_absolute_error(true_values, nn_predicted_values)\n",
    "    nn_rmse = np.sqrt(mean_squared_error(true_values, nn_predicted_values))\n",
    "    nn_r2 = r2_score(true_values, nn_predicted_values)\n",
    "\n",
    "    # Percentage-Based Prediction Error\n",
    "    nn_pred_error = np.mean(np.abs((np.array(true_values) - np.array(nn_predicted_values)) / np.array(true_values))) * 100\n",
    "\n",
    "    nn_results.append((new_app_name, nn_mae, nn_rmse, nn_r2, nn_pred_error))\n",
    "\n",
    "    print(f\"NN Prediction for {new_app_name}: MAE={nn_mae:.4f}, Prediction Accuracy={100 - nn_pred_error:.2f}%\")\n",
    "\n",
    "    ##############  Train Neural CF  ##############\n",
    "    power_pair_map = {pair: i for i, pair in enumerate(performance_matrix.index)}\n",
    "    app_map = {app: i for i, app in enumerate(performance_matrix.columns)}\n",
    "\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    \n",
    "    for app in performance_matrix.columns:\n",
    "        for power_pair in performance_matrix.index:\n",
    "            if not np.isnan(performance_matrix.at[power_pair, app]):\n",
    "                train_data.append([power_pair_map[power_pair], app_map[app]])\n",
    "                train_labels.append(performance_matrix.at[power_pair, app])\n",
    "\n",
    "    train_data = np.array(train_data)\n",
    "    train_labels = np.array(train_labels)\n",
    "\n",
    "    # Define Neural CF Model\n",
    "    num_power_pairs = len(power_pair_map)\n",
    "    num_apps = len(app_map)\n",
    "    latent_dim = 10  # Embedding size\n",
    "\n",
    "    input_power_pair = Input(shape=(1,))\n",
    "    input_app = Input(shape=(1,))\n",
    "\n",
    "    power_embedding = Embedding(num_power_pairs, latent_dim)(input_power_pair)\n",
    "    app_embedding = Embedding(num_apps, latent_dim)(input_app)\n",
    "\n",
    "    power_vec = Flatten()(power_embedding)\n",
    "    app_vec = Flatten()(app_embedding)\n",
    "\n",
    "    merged = Concatenate()([power_vec, app_vec])\n",
    "    dense_1 = Dense(128, activation='selu')(merged)\n",
    "    dense_2 = Dense(64, activation='selu')(dense_1)\n",
    "    dense_3 = Dense(32, activation='selu')(dense_2)\n",
    "    output = Dense(1, activation='linear')(dense_3)\n",
    "\n",
    "    ncf_model = Model(inputs=[input_power_pair, input_app], outputs=output)\n",
    "    ncf_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "    ncf_model.fit([train_data[:, 0], train_data[:, 1]], train_labels, epochs=25, batch_size=32, verbose=3)\n",
    "\n",
    "    ##############  Predict Missing Value via NCF  ##############\n",
    "    for power_pair in performance_matrix.index:\n",
    "        if np.isnan(performance_matrix.at[power_pair, new_app_name]):\n",
    "            power_idx = power_pair_map[power_pair]\n",
    "            app_idx = app_map[new_app_name]\n",
    "            pred_value = ncf_model.predict([np.array([power_idx]), np.array([app_idx])])[0][0]\n",
    "            performance_matrix.at[power_pair, new_app_name] = pred_value\n",
    "\n",
    "    ############### Compute CF Prediction Accuracy ##############\n",
    "    true_values = df_new.set_index(\"Power Pair\")[\"Performance\"]\n",
    "    predicted_values = performance_matrix[new_app_name].reindex(true_values.index)\n",
    "\n",
    "    cf_mae = mean_absolute_error(true_values, predicted_values)\n",
    "    cf_rmse = np.sqrt(mean_squared_error(true_values, predicted_values))\n",
    "    cf_r2 = r2_score(true_values, predicted_values)\n",
    "\n",
    "    # Percentage-Based Prediction Error\n",
    "    cf_pred_error = np.mean(np.abs((true_values - predicted_values) / true_values)) * 100\n",
    "\n",
    "    cf_results.append((new_app_name, cf_mae, cf_rmse, cf_r2, cf_pred_error))\n",
    "\n",
    "    print(f\"NCF Prediction for {new_app_name}: MAE={cf_mae:.4f}, Prediction Accuracy={100 - cf_pred_error:.2f}%\")\n",
    "\n",
    "# Convert results into a DataFrame and display\n",
    "nn_results_df = pd.DataFrame(nn_results, columns=[\"Application\", \"MAE\", \"RMSE\", \"R²\", \"Prediction Error (%)\"])\n",
    "cf_results_df = pd.DataFrame(cf_results, columns=[\"Application\", \"MAE\", \"RMSE\", \"R²\", \"Prediction Error (%)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f7789aa-acab-446b-8d3d-70cf52169e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Neural Network Prediction Accuracy ===\n",
      "sw4lite: MAE=0.0353, Prediction Accuracy=95.92%\n",
      "\n",
      "=== Neural Collaborative Filtering Prediction Accuracy ===\n",
      "sw4lite: MAE=0.0308, Prediction Accuracy=96.31%\n"
     ]
    }
   ],
   "source": [
    "# Print stored accuracy metrics after all iterations\n",
    "print(\"\\n=== Neural Network Prediction Accuracy ===\")\n",
    "for app, mae, _, _, pred_error in nn_results:\n",
    "    print(f\"{app}: MAE={mae:.4f}, Prediction Accuracy={100 - pred_error:.2f}%\")\n",
    "\n",
    "print(\"\\n=== Neural Collaborative Filtering Prediction Accuracy ===\")\n",
    "for app, mae, _, _, pred_error in cf_results:\n",
    "    print(f\"{app}: MAE={mae:.4f}, Prediction Accuracy={100 - pred_error:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4687612-0219-4644-a87a-50f9cb416fae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bfs</th>\n",
       "      <th>cfd</th>\n",
       "      <th>cfd_double</th>\n",
       "      <th>fdtd2d</th>\n",
       "      <th>gemm</th>\n",
       "      <th>gups</th>\n",
       "      <th>kmeans</th>\n",
       "      <th>lavamd</th>\n",
       "      <th>maxflops</th>\n",
       "      <th>nw</th>\n",
       "      <th>...</th>\n",
       "      <th>Resnet50</th>\n",
       "      <th>sw4lite</th>\n",
       "      <th>Laghos</th>\n",
       "      <th>NAMD</th>\n",
       "      <th>miniGAN</th>\n",
       "      <th>gromacs</th>\n",
       "      <th>bert_large</th>\n",
       "      <th>UNet</th>\n",
       "      <th>CRADL</th>\n",
       "      <th>XSBench</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(120, 150)</th>\n",
       "      <td>0.637024</td>\n",
       "      <td>0.637359</td>\n",
       "      <td>0.818064</td>\n",
       "      <td>0.733109</td>\n",
       "      <td>0.638716</td>\n",
       "      <td>0.970849</td>\n",
       "      <td>0.899788</td>\n",
       "      <td>0.656863</td>\n",
       "      <td>0.716044</td>\n",
       "      <td>0.615326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.748207</td>\n",
       "      <td>0.593205</td>\n",
       "      <td>0.645191</td>\n",
       "      <td>0.620911</td>\n",
       "      <td>0.679260</td>\n",
       "      <td>0.684636</td>\n",
       "      <td>0.806175</td>\n",
       "      <td>0.686133</td>\n",
       "      <td>0.640825</td>\n",
       "      <td>0.581656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(120, 160)</th>\n",
       "      <td>0.601343</td>\n",
       "      <td>0.630359</td>\n",
       "      <td>0.843605</td>\n",
       "      <td>0.785478</td>\n",
       "      <td>0.636686</td>\n",
       "      <td>0.985136</td>\n",
       "      <td>0.899804</td>\n",
       "      <td>0.671545</td>\n",
       "      <td>0.753145</td>\n",
       "      <td>0.634912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763345</td>\n",
       "      <td>0.579719</td>\n",
       "      <td>0.640847</td>\n",
       "      <td>0.611251</td>\n",
       "      <td>0.696895</td>\n",
       "      <td>0.690649</td>\n",
       "      <td>0.823847</td>\n",
       "      <td>0.692480</td>\n",
       "      <td>0.634400</td>\n",
       "      <td>0.594419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(120, 170)</th>\n",
       "      <td>0.637012</td>\n",
       "      <td>0.630417</td>\n",
       "      <td>0.843523</td>\n",
       "      <td>0.845871</td>\n",
       "      <td>0.642886</td>\n",
       "      <td>0.985148</td>\n",
       "      <td>0.918240</td>\n",
       "      <td>0.656853</td>\n",
       "      <td>0.773292</td>\n",
       "      <td>0.624922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.756815</td>\n",
       "      <td>0.594429</td>\n",
       "      <td>0.642583</td>\n",
       "      <td>0.613256</td>\n",
       "      <td>0.725310</td>\n",
       "      <td>0.703670</td>\n",
       "      <td>0.829256</td>\n",
       "      <td>0.704401</td>\n",
       "      <td>0.640516</td>\n",
       "      <td>0.590241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(120, 180)</th>\n",
       "      <td>0.632312</td>\n",
       "      <td>0.630321</td>\n",
       "      <td>0.870889</td>\n",
       "      <td>0.879836</td>\n",
       "      <td>0.644969</td>\n",
       "      <td>0.985232</td>\n",
       "      <td>0.918253</td>\n",
       "      <td>0.633694</td>\n",
       "      <td>0.743598</td>\n",
       "      <td>0.615301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761961</td>\n",
       "      <td>0.588311</td>\n",
       "      <td>0.640753</td>\n",
       "      <td>0.590209</td>\n",
       "      <td>0.728197</td>\n",
       "      <td>0.712597</td>\n",
       "      <td>0.847633</td>\n",
       "      <td>0.714047</td>\n",
       "      <td>0.640477</td>\n",
       "      <td>0.570782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(120, 190)</th>\n",
       "      <td>0.637010</td>\n",
       "      <td>0.630438</td>\n",
       "      <td>0.870746</td>\n",
       "      <td>0.916513</td>\n",
       "      <td>0.642902</td>\n",
       "      <td>0.999798</td>\n",
       "      <td>0.918217</td>\n",
       "      <td>0.666623</td>\n",
       "      <td>0.743510</td>\n",
       "      <td>0.624946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.757247</td>\n",
       "      <td>0.599265</td>\n",
       "      <td>0.646845</td>\n",
       "      <td>0.587302</td>\n",
       "      <td>0.741272</td>\n",
       "      <td>0.717044</td>\n",
       "      <td>0.858999</td>\n",
       "      <td>0.712057</td>\n",
       "      <td>0.634252</td>\n",
       "      <td>0.559531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(200, 210)</th>\n",
       "      <td>0.988398</td>\n",
       "      <td>0.983083</td>\n",
       "      <td>0.964160</td>\n",
       "      <td>0.999803</td>\n",
       "      <td>0.970615</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.999771</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984617</td>\n",
       "      <td>0.986726</td>\n",
       "      <td>1.012247</td>\n",
       "      <td>0.991432</td>\n",
       "      <td>0.990818</td>\n",
       "      <td>0.984795</td>\n",
       "      <td>0.977278</td>\n",
       "      <td>0.963588</td>\n",
       "      <td>0.982609</td>\n",
       "      <td>0.978682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(200, 220)</th>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.983148</td>\n",
       "      <td>0.964155</td>\n",
       "      <td>0.999816</td>\n",
       "      <td>0.990035</td>\n",
       "      <td>0.999869</td>\n",
       "      <td>0.999768</td>\n",
       "      <td>0.978321</td>\n",
       "      <td>0.983114</td>\n",
       "      <td>0.975661</td>\n",
       "      <td>...</td>\n",
       "      <td>1.002311</td>\n",
       "      <td>0.945251</td>\n",
       "      <td>0.983839</td>\n",
       "      <td>0.953184</td>\n",
       "      <td>0.972923</td>\n",
       "      <td>0.968834</td>\n",
       "      <td>0.973787</td>\n",
       "      <td>0.963600</td>\n",
       "      <td>0.962764</td>\n",
       "      <td>0.927079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(200, 230)</th>\n",
       "      <td>0.999982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964168</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>0.995034</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.966676</td>\n",
       "      <td>0.975567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997511</td>\n",
       "      <td>0.922074</td>\n",
       "      <td>0.982641</td>\n",
       "      <td>0.952342</td>\n",
       "      <td>0.973780</td>\n",
       "      <td>0.964614</td>\n",
       "      <td>0.971409</td>\n",
       "      <td>0.946061</td>\n",
       "      <td>0.948404</td>\n",
       "      <td>0.915300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(200, 240)</th>\n",
       "      <td>0.999965</td>\n",
       "      <td>0.983124</td>\n",
       "      <td>0.999882</td>\n",
       "      <td>0.999814</td>\n",
       "      <td>0.989992</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.988977</td>\n",
       "      <td>0.983013</td>\n",
       "      <td>0.869468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986865</td>\n",
       "      <td>0.953991</td>\n",
       "      <td>1.009568</td>\n",
       "      <td>0.992875</td>\n",
       "      <td>0.950191</td>\n",
       "      <td>0.962752</td>\n",
       "      <td>0.976246</td>\n",
       "      <td>0.978114</td>\n",
       "      <td>0.947420</td>\n",
       "      <td>0.981660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(200, 250)</th>\n",
       "      <td>0.988516</td>\n",
       "      <td>0.983044</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.999803</td>\n",
       "      <td>0.990102</td>\n",
       "      <td>0.985166</td>\n",
       "      <td>0.999806</td>\n",
       "      <td>0.988977</td>\n",
       "      <td>0.966643</td>\n",
       "      <td>0.952318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998861</td>\n",
       "      <td>0.905228</td>\n",
       "      <td>0.980246</td>\n",
       "      <td>0.941115</td>\n",
       "      <td>0.938624</td>\n",
       "      <td>0.957326</td>\n",
       "      <td>0.971000</td>\n",
       "      <td>0.963974</td>\n",
       "      <td>0.959275</td>\n",
       "      <td>0.917863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bfs       cfd  cfd_double    fdtd2d      gemm      gups  \\\n",
       "(120, 150)  0.637024  0.637359    0.818064  0.733109  0.638716  0.970849   \n",
       "(120, 160)  0.601343  0.630359    0.843605  0.785478  0.636686  0.985136   \n",
       "(120, 170)  0.637012  0.630417    0.843523  0.845871  0.642886  0.985148   \n",
       "(120, 180)  0.632312  0.630321    0.870889  0.879836  0.644969  0.985232   \n",
       "(120, 190)  0.637010  0.630438    0.870746  0.916513  0.642902  0.999798   \n",
       "...              ...       ...         ...       ...       ...       ...   \n",
       "(200, 210)  0.988398  0.983083    0.964160  0.999803  0.970615  0.999860   \n",
       "(200, 220)  0.999967  0.983148    0.964155  0.999816  0.990035  0.999869   \n",
       "(200, 230)  0.999982  1.000000    0.964168  0.999852  0.995034  0.999899   \n",
       "(200, 240)  0.999965  0.983124    0.999882  0.999814  0.989992  0.999878   \n",
       "(200, 250)  0.988516  0.983044    0.999986  0.999803  0.990102  0.985166   \n",
       "\n",
       "              kmeans    lavamd  maxflops        nw  ...  Resnet50   sw4lite  \\\n",
       "(120, 150)  0.899788  0.656863  0.716044  0.615326  ...  0.748207  0.593205   \n",
       "(120, 160)  0.899804  0.671545  0.753145  0.634912  ...  0.763345  0.579719   \n",
       "(120, 170)  0.918240  0.656853  0.773292  0.624922  ...  0.756815  0.594429   \n",
       "(120, 180)  0.918253  0.633694  0.743598  0.615301  ...  0.761961  0.588311   \n",
       "(120, 190)  0.918217  0.666623  0.743510  0.624946  ...  0.757247  0.599265   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "(200, 210)  0.999771  0.999971  1.000000  0.999959  ...  0.984617  0.986726   \n",
       "(200, 220)  0.999768  0.978321  0.983114  0.975661  ...  1.002311  0.945251   \n",
       "(200, 230)  1.000000  0.999954  0.966676  0.975567  ...  0.997511  0.922074   \n",
       "(200, 240)  0.999878  0.988977  0.983013  0.869468  ...  0.986865  0.953991   \n",
       "(200, 250)  0.999806  0.988977  0.966643  0.952318  ...  0.998861  0.905228   \n",
       "\n",
       "              Laghos      NAMD   miniGAN   gromacs  bert_large      UNet  \\\n",
       "(120, 150)  0.645191  0.620911  0.679260  0.684636    0.806175  0.686133   \n",
       "(120, 160)  0.640847  0.611251  0.696895  0.690649    0.823847  0.692480   \n",
       "(120, 170)  0.642583  0.613256  0.725310  0.703670    0.829256  0.704401   \n",
       "(120, 180)  0.640753  0.590209  0.728197  0.712597    0.847633  0.714047   \n",
       "(120, 190)  0.646845  0.587302  0.741272  0.717044    0.858999  0.712057   \n",
       "...              ...       ...       ...       ...         ...       ...   \n",
       "(200, 210)  1.012247  0.991432  0.990818  0.984795    0.977278  0.963588   \n",
       "(200, 220)  0.983839  0.953184  0.972923  0.968834    0.973787  0.963600   \n",
       "(200, 230)  0.982641  0.952342  0.973780  0.964614    0.971409  0.946061   \n",
       "(200, 240)  1.009568  0.992875  0.950191  0.962752    0.976246  0.978114   \n",
       "(200, 250)  0.980246  0.941115  0.938624  0.957326    0.971000  0.963974   \n",
       "\n",
       "               CRADL   XSBench  \n",
       "(120, 150)  0.640825  0.581656  \n",
       "(120, 160)  0.634400  0.594419  \n",
       "(120, 170)  0.640516  0.590241  \n",
       "(120, 180)  0.640477  0.570782  \n",
       "(120, 190)  0.634252  0.559531  \n",
       "...              ...       ...  \n",
       "(200, 210)  0.982609  0.978682  \n",
       "(200, 220)  0.962764  0.927079  \n",
       "(200, 230)  0.948404  0.915300  \n",
       "(200, 240)  0.947420  0.981660  \n",
       "(200, 250)  0.959275  0.917863  \n",
       "\n",
       "[99 rows x 28 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0284b39c-2cd1-4d1a-abd2-2a4495869e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_matrix.to_csv(\"./prediction_res/performance_matrix.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f22ef3d-e36f-40af-880e-b38813af6c31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
